{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum display option for columns and rows\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PER GAME STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBA season we will be analyzing\n",
    "year = 2020\n",
    "\n",
    "# URL page we will scraping- {} is for the year\n",
    "url = \"https://www.basketball-reference.com/leagues/NBA_{}_per_game.html\".format(year)\n",
    "\n",
    "# this is the HTML from the given URL\n",
    "html = urlopen(url)\n",
    "\n",
    "#BeautifulSoup function passed through the entire web page in order to convert it into an object\n",
    "soup = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use findALL() to get the column headers ,'tr' is the HTML tag for the table row, limit = 2 is for the first two rows\n",
    "soup.findAll('tr', limit=2)\n",
    "\n",
    "# use getText()to extract the text we need into a list\n",
    "headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
    "\n",
    "# exclude the first column as we will not need the ranking order from Basketball Reference for the analysis\n",
    "headers = headers[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step, we will extract the data from the cells of the table in order to add it to our DataFrame. \n",
    "# Although it is similar to extracting data from column header, the data within the cell, \n",
    "# in this case player stats, is in a 2-dimensional format. Therefore, we must set up a 2-dimensional list:\n",
    "\n",
    "# avoid the first header row\n",
    "rows = soup.findAll('tr')[1:]\n",
    "player_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
    "            for i in range(len(rows))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data and the clumn headers to create a dataframe\n",
    "stats = pd.DataFrame(player_stats, columns = headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADVANCED STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBA season we will be analyzing\n",
    "year = 2020\n",
    "\n",
    "# URL page we will scraping- {} is for the year\n",
    "url_adv = \"https://www.basketball-reference.com/leagues/NBA_{}_advanced.html\".format(year) \n",
    "\n",
    "# this is the HTML from the given URL\n",
    "html_adv = urlopen(url_adv)\n",
    "\n",
    "#BeautifulSoup function passed through the entire web page in order to convert it into an object\n",
    "soup_adv = BeautifulSoup(html_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use findALL() to get the column headers ,'tr' is the HTML tag for the table row, limit = 2 is for the first two rows\n",
    "soup_adv.findAll('tr', limit=2)\n",
    "\n",
    "# use getText()to extract the text we need into a list\n",
    "headers_adv = [th.getText() for th in soup_adv.findAll('tr', limit=2)[0].findAll('th')]\n",
    "\n",
    "# exclude the first column as we will not need the ranking order from Basketball Reference for the analysis\n",
    "headers_adv = headers_adv[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step, we will extract the data from the cells of the table in order to add it to our DataFrame. \n",
    "# Although it is similar to extracting data from column header, the data within the cell, \n",
    "# in this case player stats, is in a 2-dimensional format. Therefore, we must set up a 2-dimensional list:\n",
    "\n",
    "# avoid the first header row\n",
    "rows_adv = soup_adv.findAll('tr')[1:]\n",
    "player_stats_adv = [[td.getText() for td in rows_adv[i].findAll('td')]\n",
    "            for i in range(len(rows_adv))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data and the clumn headers to create a dataframe\n",
    "stats_adv = pd.DataFrame(player_stats_adv, columns = headers_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMBINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes\n",
    "stats_2020 = pd.merge(stats, stats_adv,  how='left', left_on=['Player','Tm'], right_on = ['Player','Tm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate columns\n",
    "stats_2020.drop(['Pos_y','Age_y','G_y', 'MP_y'], axis=1, inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "stats_2020 = stats_2020.rename(columns={'Pos_x': 'Pos','Age_x': 'Age','G_x': 'G','MP_x': 'MP'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates and reset index\n",
    "stats_2020 = stats_2020.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace empty values and nas with 0\n",
    "stats_2020 = stats_2020.replace('', 0)\n",
    "stats_2020 = stats_2020.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the categorical values\n",
    "stats_2020['Player'] = stats_2020['Player'].astype('category')\n",
    "stats_2020['Pos'] = stats_2020['Pos'].astype('category')\n",
    "stats_2020['Age'] = stats_2020['Age'].astype('category')\n",
    "stats_2020['Tm'] = stats_2020['Tm'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numeric values\n",
    "for col in ['G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
    "       '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB',\n",
    "       'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'PER', 'TS%',\n",
    "       '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%',\n",
    "       'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM',\n",
    "       'VORP']:\n",
    "    stats_2020[col] =pd.to_numeric(stats_2020[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the empty columns\n",
    "stats_2020.drop(stats_2020.select_dtypes(['object']), inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_2020['Year']= 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with TOT and rename Team\n",
    "stats_2020 = stats_2020[stats_2020['Tm'] != 'TOT']\n",
    "stats_2020 =stats_2020.rename(columns={'Tm': 'Team'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the data and filter with rows with GP >10 and MP >5\n",
    "stats_2020 = stats_2020[(stats_2020['G'] >= 10) & (stats_2020['MP'] >= 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the numeric values\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "test = stats_2020.select_dtypes(include=numerics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the two empty columns by index\n",
    "cols = [41,46]\n",
    "stats_2020.drop(stats_2020.columns[cols],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats_2020.to_csv('/data/Season_Stats(2020).csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
