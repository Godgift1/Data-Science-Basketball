{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum display option for columns and rows\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBA season we will be analyzing\n",
    "year = 2018\n",
    "\n",
    "# URL page we will scraping- {} is for the year\n",
    "url_adv = \"https://www.basketball-reference.com/awards/awards_2019.html\".format(year) \n",
    "\n",
    "# this is the HTML from the given URL\n",
    "html_adv = urlopen(url_adv)\n",
    "\n",
    "#BeautifulSoup function passed through the entire web page in order to convert it into an object\n",
    "soup_adv = BeautifulSoup(html_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use findALL() to get the column headers ,'tr' is the HTML tag for the table row, limit = 2 is for the first two rows\n",
    "soup_adv.findAll('tr', limit=2)\n",
    "\n",
    "# use getText()to extract the text we need into a list\n",
    "headers_adv = [th.getText() for th in soup_adv.findAll('tr', limit=2)[1].findAll('th')]\n",
    "\n",
    "# exclude the first column as we will not need the ranking order from Basketball Reference for the analysis\n",
    "headers_adv = headers_adv[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step, we will extract the data from the cells of the table in order to add it to our DataFrame. \n",
    "# Although it is similar to extracting data from column header, the data within the cell, \n",
    "# in this case player stats, is in a 2-dimensional format. Therefore, we must set up a 2-dimensional list:\n",
    "\n",
    "# avoid the first header row\n",
    "rows_adv = soup_adv.findAll('tr')[2:14]\n",
    "team_stats_adv = [[td.getText() for td in rows_adv[i].findAll('td')]\n",
    "            for i in range(len(rows_adv))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data and the clumn headers to create a dataframe\n",
    "stats_adv = pd.DataFrame(team_stats_adv, columns = headers_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats_adv.to_csv('/data/Test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
      "\u001b[K    100% |████████████████████████████████| 911kB 894kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3 in /opt/conda/lib/python3.6/site-packages (from selenium)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
